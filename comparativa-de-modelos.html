<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Comparativa de Modelos - DocumentacionASI</title><meta name="description" content="Comparativa de Modelos - Carla Arribas Muñoz El objetivo de esta práctica ha sido poner a prueba distintos modelos de IA en LM Studio pasándoles algunos arcetijos. En base a sus respuestas, y teniendo en cuenta los tokens por segundo, tokens totales, tiempo de respuesta,&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://carla38.github.io/2damasi/comparativa-de-modelos.html"><link rel="alternate" type="application/atom+xml" href="https://carla38.github.io/2damasi/feed.xml" title="DocumentacionASI - RSS"><link rel="alternate" type="application/json" href="https://carla38.github.io/2damasi/feed.json" title="DocumentacionASI - JSON"><meta property="og:title" content="Comparativa de Modelos"><meta property="og:site_name" content="DocumentacionASI"><meta property="og:description" content="Comparativa de Modelos - Carla Arribas Muñoz El objetivo de esta práctica ha sido poner a prueba distintos modelos de IA en LM Studio pasándoles algunos arcetijos. En base a sus respuestas, y teniendo en cuenta los tokens por segundo, tokens totales, tiempo de respuesta,&hellip;"><meta property="og:url" content="https://carla38.github.io/2damasi/comparativa-de-modelos.html"><meta property="og:type" content="article"><link rel="stylesheet" href="https://carla38.github.io/2damasi/assets/css/style.css?v=7d5bbddb88a13bb0ad0ef21985ae0d0a"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://carla38.github.io/2damasi/comparativa-de-modelos.html"},"headline":"Comparativa de Modelos","datePublished":"2025-12-07T00:07+01:00","dateModified":"2025-12-07T20:14+01:00","description":"Comparativa de Modelos - Carla Arribas Muñoz El objetivo de esta práctica ha sido poner a prueba distintos modelos de IA en LM Studio pasándoles algunos arcetijos. En base a sus respuestas, y teniendo en cuenta los tokens por segundo, tokens totales, tiempo de respuesta,&hellip;","author":{"@type":"Person","name":"Carla","url":"https://carla38.github.io/2damasi/authors/carla/"},"publisher":{"@type":"Organization","name":"Carla"}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="post-template"><header class="top js-header"><a class="logo" href="https://carla38.github.io/2damasi/">DocumentacionASI</a></header><main class="post"><article class="content"><div class="hero hero--noimage"><header class="hero__content"><div class="wrapper"><h1>Comparativa de Modelos</h1><div class="feed__meta content__meta"><time datetime="2025-12-07T00:07" class="feed__date">December 7, 2025</time></div></div></header></div><div class="entry-wrapper content__entry"><p class="align-center"><span style="text-decoration: underline;"><span style="color: #000000; text-decoration: underline;"><strong>Comparativa de Modelos - Carla Arribas Muñoz</strong></span></span></p><p>El objetivo de esta práctica ha sido poner a prueba distintos modelos de IA en LM Studio pasándoles algunos arcetijos. En base a sus respuestas, y teniendo en cuenta los tokens por segundo, tokens totales, tiempo de respuesta, etc.., hemos hecho una comparativa de los distintos modelos probados.</p><p class="align-left">Por falta de tiempo, únicamente pudimos probar 3 acertijos en 2 modelos distintos. Pero para está práctica también se incluirá una prueba realizada desde la Jetson Nano, en la cuál, desde la terminal usando Ollama, pedimos a la IA que nos contara un cuento.</p><p> </p><p class="align-center"><strong>Ollama</strong></p><p class="align-left">Para installar Ollama en la Jetson Nano (Linux) habrá que introducir el siguiente comando:</p><p class="align-left"><strong>curl -fsSL https://ollama.com/install.sh | sh</strong></p><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0002.jpg" alt="" width="558" height="314" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0002-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0002-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0002-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0002-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0002-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0002-2xl.jpg 1920w"></figure><p class="align-left">Al acabar la instalación, podremos ejecutar cualquiera de los modelos que ofrecen. En nuestro caso ejecutamos el modelo Qwen3 8B usando el siguiente comando:</p><p class="align-left"><strong>ollama run qwen3:8b --verbose</strong></p><p class="align-left">El prompt que le dimos a la IA en este caso fue que nos contara un cuento de 500 palabras. En esta captura se muestra su respuesta junto a otra información, como la duración y los tokens:</p><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0008.jpg" alt="" width="560" height="315" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0008-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0008-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0008-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0008-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0008-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0008-2xl.jpg 1920w"></figure><p> </p><p class="align-center"><strong>LM Studio</strong></p><p>Desde la Mac Mini hicimos las pruebas con 2 modelos en LM Studio. Usamos los modelos Granite 4 H Tiny y Qwen VL 4B. Los acertijos propuestos fueron los siguientes:</p><ul><li>Tengo ciudades, pero no casas; tengo montañas, pero no árboles; tengo agua, pero no peces. ¿Qué soy?</li><li>Cuanto más quitas, más grande se hace. ¿Qué es?</li><li>No tiene boca pero habla, no tiene oídos pero escucha. Si lo llamas, responde. ¿Qué es?</li></ul><p><strong>-Respuestas de Granite 4H Tiny</strong></p><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0011.jpg" alt="" width="567" height="319" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0011-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0011-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0011-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0011-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0011-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0011-2xl.jpg 1920w"></figure><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0012.jpg" alt="" width="569" height="320" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0012-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0012-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0012-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0012-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0012-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0012-2xl.jpg 1920w"></figure><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0013.jpg" alt="" width="567" height="319" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0013-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0013-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0013-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0013-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0013-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0013-2xl.jpg 1920w"></figure><p> </p><p><strong>-Respuestas de Qwen VL 4B</strong></p><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0015-2.jpg" alt="" width="567" height="596" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0015-2-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0015-2-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0015-2-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0015-2-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0015-2-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0015-2-2xl.jpg 1920w"></figure><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0016.jpg" alt="" width="566" height="625" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0016-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0016-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0016-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0016-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0016-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0016-2xl.jpg 1920w"></figure><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0017.jpg" alt="" width="565" height="649" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0017-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0017-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0017-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0017-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0017-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0017-2xl.jpg 1920w"></figure><p> </p><p class="align-center"><strong>Conclusiones</strong></p><p>Como conclusión general a partir de las capturas, se puede observar que tanto Qwen3 8B en la Jetson como Granite en LM Studio han sido capaces de dar una respuesta acorde a lo solicitado, mientras que Qwen3 4B ha entrado en un bucle para los 2 últimos acertijos, teniendo que ser detenido directamente por nosotros. Los resultados finales han sido los siguientes:</p><p><strong>Qwen 3 8B</strong></p><ul><li>Tokens por segundo : 7,68 tk/s</li><li>Tokens totales : 1175 tks</li></ul><p><strong>Granite 4H Tiny</strong></p><p>-<span style="text-decoration: underline;"><span style="color: #000000; text-decoration: underline;">Acertijo 1</span></span></p><ul><li>Tokens por segundo : 44,48 tk/s</li><li>Tokens totales : 49 tks</li><li>Tiempo primer token : 0,24 s</li><li>Respuesta : Acertada</li></ul><p>-<span style="text-decoration: underline;">Acertijo 2</span></p><ul><li>Tokens por segundo : 45.70 tk/s</li><li>Tokens totales : 32 tks</li><li>Tiempo primer token : 0,38 s</li><li>Respuesta : Acertada</li></ul><p>-<span style="text-decoration: underline;">Acertijo 3</span></p><ul><li>Tokens por segundo : 44,78 tk/s</li><li>Tokens totales : 50 tks</li><li>Tiempo primer token : 0,20 s</li><li>Respuesta : Acertada</li></ul><p><strong>Qwen 3 4B</strong></p><p>-<span style="text-decoration: underline;">Acertijo 1</span></p><ul><li>Tokens por segundo : 39,18 tk/s</li><li>Tokens totales : 520 tks</li><li>Tiempo primer token : 0,58 s</li><li>Respuesta : Acertada</li></ul><p>-<span style="text-decoration: underline;">Acertijo 2</span></p><ul><li>Tokens por segundo : 35,22 tk/s</li><li>Tokens totales : 1372 tks</li><li>Tiempo primer token : 2,46 s</li><li>Respuesta : Fallida. Bucle.</li></ul><p>-<span style="text-decoration: underline;">Acertijo 3</span></p><ul><li>Tokens por segundo : 32,09 tk/s</li><li>Tokens totales : 626 tks</li><li>Tiempo primer token : 6,18 s</li><li>Respuesta : Fallida. Bucle.</li></ul><p> </p><p> </p><p> </p></div></article></main><footer class="footer"><div class="wrapper"><div class="footer__copyright"><p>DocumentacionASI - Carla Arribas</p></div><button id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg width="20" height="20"><use xlink:href="https://carla38.github.io/2damasi/assets/svg/svg-map.svg#toparrow"/></svg></button></div></footer><script defer="defer" src="https://carla38.github.io/2damasi/assets/js/scripts.min.js?v=700105c316933a8202041b6415abb233"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>