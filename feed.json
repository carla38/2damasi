{
    "version": "https://jsonfeed.org/version/1",
    "title": "DocumentacionASI",
    "description": "",
    "home_page_url": "https://carla38.github.io/2damasi",
    "feed_url": "https://carla38.github.io/2damasi/feed.json",
    "user_comment": "",
    "author": {
        "name": "Carla"
    },
    "items": [
        {
            "id": "https://carla38.github.io/2damasi/manual-fine-tunning.html",
            "url": "https://carla38.github.io/2damasi/manual-fine-tunning.html",
            "title": "Manual Fine Tunning",
            "summary": "En este manual se documentará el proceso seguido durante la práctica del Fine Tunning. El Fine Tunning en Inteligencia Artificial consiste en ajustar un modelo preexistente para que aprenda nueva información o pueda desarrollar tareas específicas. Para esta tarea el modelo que hemos elegido para&hellip;",
            "content_html": "<p>En este manual se documentará el proceso seguido durante la práctica del <strong>Fine Tunning</strong>.</p>\n<p>El Fine Tunning en Inteligencia Artificial consiste en ajustar un modelo preexistente para que aprenda nueva información o pueda desarrollar tareas específicas.</p>\n<p>Para esta tarea el modelo que hemos elegido para realizar el Fine Tunning es <strong>Llama-3.2-1B.</strong></p>\n<hr>\n<p class=\"align-center\"><strong>Paso 1</strong></p>\n<p>Previamente hemos preparado un directorio en el que guardará el modelo resultante del proceso y un archivo <strong>.json</strong> con los nuevos datos que aprenderá el modelo. </p>\n<p>Primero, usando el comando <strong>python3 -m pip install mlx-lm huggingface_hub</strong> descargamos las librerías necesarias.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/7/IMG-20260130-WA0001.jpg\" alt=\"\" width=\"636\" height=\"358\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0001-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0001-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0001-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0001-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0001-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0001-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p class=\"align-center\"><strong>Paso 2</strong></p>\n<p>Con <strong>cp train.jsonl valid.jsonl</strong> se crea una copia de los datos, ya que <strong>MLX</strong>, la librería que se está usando para el entrenamiento, requiere un set de validación.</p>\n<p>El segundo comando que se muestra en la captura lanza el proceso de entrenamiento. En la captura se muestran 100 iteraciones, pero más tarde se incrementaron para que el modelo pudiera aprender mejor la nueva información.</p>\n<p>Al acabar, guarda los adapters, el conocimiento nuevo, en la carpeta <strong>adapters</strong></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/7/IMG-20260130-WA0003.jpg\" alt=\"\" width=\"645\" height=\"363\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0003-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0003-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0003-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0003-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0003-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0003-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p class=\"align-center\"><strong>Paso 3</strong></p>\n<p>Se ejecuta un proceso de fusión que une el modelo original con los adapters generados en el paso anterior, dando como resultado un modelo nuevo derivado del original pero con la nueva información. Este modelo se guarda en la carpeta <strong>modelo-daniel-fusionado</strong>.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/7/IMG-20260130-WA0004-2.jpg\" alt=\"\" width=\"638\" height=\"148\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0004-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0004-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0004-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0004-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0004-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0004-2-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p class=\"align-center\"><strong>Paso 5</strong></p>\n<p>Se instalan dependencias necesarias para convertir el modelo a formato <strong>.gguf</strong>.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/7/IMG-20260130-WA0005-2.jpg\" alt=\"\" width=\"649\" height=\"365\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0005-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0005-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0005-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0005-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0005-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0005-2-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/7/IMG-20260130-WA0006.jpg\" alt=\"\" width=\"645\" height=\"363\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0006-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0006-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0006-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0006-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0006-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0006-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p class=\"align-center\"><strong>Prueba Final</strong></p>\n<p>Ejecutando el siguiente comando: </p>\n<p><strong>python3 -m mlx_lm.chat \\</strong><br><strong>--model mlx-community/Llama-3.2-1B-Instruct-4bit \\</strong><br><strong>--adapter-path adapters</strong> </p>\n<p>Se abrirá una interfaz para poder chatear con el modelo. Al preguntarle '¿Quién es Daniel Terroba?', el modelo responde con la información que ha aprendido del entrenamiento.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/7/IMG-20260130-WA0009.jpg\" alt=\"\" width=\"665\" height=\"374\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0009-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0009-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0009-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0009-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0009-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0009-2xl.jpg 1920w\"></figure>\n<p> </p>",
            "author": {
                "name": "Carla"
            },
            "tags": [
            ],
            "date_published": "2026-02-08T23:23:38+01:00",
            "date_modified": "2026-02-08T23:38:56+01:00"
        },
        {
            "id": "https://carla38.github.io/2damasi/manual-pre-entrenamiento.html",
            "url": "https://carla38.github.io/2damasi/manual-pre-entrenamiento.html",
            "title": "Manual Pre-Entrenamiento",
            "summary": "En este manual se redactará el proceso seguido en el aula para realizar la tarea de Pre-Entrenamiento. En Inteligencia Artificial, el pre-entrenamiento consiste en entrenar un modelo de lenguaje a partir de una cierta cantidad de datos, para que el modelo pueda desarrollar patrones y&hellip;",
            "content_html": "<p>En este manual se redactará el proceso seguido en el aula para realizar la tarea de Pre-Entrenamiento.</p>\n<p>En Inteligencia Artificial, el pre-entrenamiento consiste en entrenar un modelo de lenguaje a partir de una cierta cantidad de datos, para que el modelo pueda desarrollar patrones y conocimientos antes de realizar una tarea.</p>\n<p>Durante este proceso hemos utilizado el modelo de lenguaje pequeño <strong>Nano-Llama</strong>, y le hemos entrenado en base a el libro <strong>Don Quijote de la Mancha</strong>.</p>\n<hr>\n<p class=\"align-center\"><strong>Paso 1</strong></p>\n<p>Primero, partiendo de un directorio creado previamente, hemos creado y activado un <strong>entorno virtual</strong>, desde el cual se realizarán todos los pasos posteriores. También se han instalado las librerías necesarias y el libro Don Quijote de la Mancha.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/6/IMG-20260129-WA0001.jpg\" alt=\"\" width=\"586\" height=\"330\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0001-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0001-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0001-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0001-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0001-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0001-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/6/IMG-20260129-WA0002.jpg\" alt=\"\" width=\"585\" height=\"329\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0002-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0002-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0002-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0002-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0002-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0002-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/6/IMG-20260129-WA0003-2.jpg\" alt=\"\" width=\"584\" height=\"194\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0003-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0003-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0003-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0003-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0003-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0003-2-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p class=\"align-center\"><strong>Paso 2</strong></p>\n<p>Mediante <strong>touch 1_tokenizador.p</strong>y y <strong>python3 1_tokenizador.py</strong> se ejecuta dicho script creado anteriormente, que se encarga de analizar el texto del Quijote y de simplificarlo en tokens para que la IA sea capaz de leer las palabras. Este proceso se llama <strong>Tokenización</strong>, y generará el archivo <strong>tokenizer.model</strong>. </p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/6/IMG-20260129-WA0004.jpg\" alt=\"\" width=\"597\" height=\"336\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0004-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0004-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0004-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0004-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0004-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0004-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p class=\"align-center\"><strong>Paso 3</strong></p>\n<p>Se inicia el entrenamiento con <strong>python3 2_entrenar.py</strong>. Durante este proceso la red neuronal leerá el libro una y otra vez, hasta ser capaz de predecir la siguiente palabra. Al finalizar el proceso de entrenamiento, el modelo resultante se guarda en la carpeta <strong>quijote_final</strong>.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/6/IMG-20260129-WA0009.jpg\" alt=\"\" width=\"621\" height=\"291\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0009-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0009-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0009-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0009-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0009-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0009-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/6/IMG-20260129-WA0010.jpg\" alt=\"\" width=\"620\" height=\"349\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0010-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0010-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0010-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0010-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0010-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0010-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p class=\"align-center\"><strong>Paso 4</strong></p>\n<p>Para poder utilizar el modelo, habrá que pasarlo a formato <strong>.gguf</strong>. Este proceso usará el script de conversión <strong>convert_hf_to_gguf.py</strong> dará como resultado el archivo <strong>quijote.gguf</strong>.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/6/IMG-20260129-WA0011.jpg\" alt=\"\" width=\"618\" height=\"293\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0011-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0011-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0011-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0011-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0011-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0011-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/6/IMG-20260129-WA0012.jpg\" alt=\"\" width=\"618\" height=\"348\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0012-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0012-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0012-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0012-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0012-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0012-2xl.jpg 1920w\"></figure>\n<hr>\n<p class=\"align-center\"><strong>Prueba final</strong></p>\n<p>Al usar el modelo conseguido e introducir el inicio del libro \"En un lugar de la Mancha\", el resultado obtenido ha sido el que se muestra en la imágen. Aunque la respuesta sea bastante incoherente, es posible que se deba al tamaño del modelo y/o la falta de datos proporcionados para el entrenamiento.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/6/IMG-20260129-WA0013-2.jpg\" alt=\"\" width=\"1552\" height=\"327\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0013-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0013-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0013-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0013-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0013-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/6/responsive/IMG-20260129-WA0013-2-2xl.jpg 1920w\"></figure>",
            "author": {
                "name": "Carla"
            },
            "tags": [
            ],
            "date_published": "2026-02-07T21:45:20+01:00",
            "date_modified": "2026-02-07T21:45:20+01:00"
        },
        {
            "id": "https://carla38.github.io/2damasi/manual-agente.html",
            "url": "https://carla38.github.io/2damasi/manual-agente.html",
            "title": "Manual Agente",
            "summary": "El objetivo de esta tarea es usar un agente con una IA local. Un agente es un programa capaz de recopilar y procesar datos para poder realizar tareas específicas establecidas por el usuario. Es decir, el usuario le dará una tarea al agente, y este&hellip;",
            "content_html": "<p>El objetivo de esta tarea es usar un agente con una IA local. Un agente es un programa capaz de recopilar y procesar datos para poder realizar tareas específicas establecidas por el usuario. Es decir, el usuario le dará una tarea al agente, y este decidirá las acciones que tomará para cumplir con el objetivo. </p>\n<p>Para esta tarea se usará el agente <strong>OpenCode</strong>, y se mostrará el proceso realizado con el modelo <strong>GPT OSS 20B</strong>.</p>\n<hr>\n<p class=\"align-center\"><strong>Paso 1</strong></p>\n<p>Lo primero es instalar el agente OpenCode desde la terminal, lo cual se hace con el comando <strong>curl -fsSL https://opencode.ai/install<a rel=\"nofollow\"></a> | bash</strong></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/5/IMG-20260123-WA0001.jpg\" alt=\"\" width=\"620\" height=\"349\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0001-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0001-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0001-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0001-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0001-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0001-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p class=\"align-center\"><strong>Paso 2</strong></p>\n<p>Para abrir OpenCode, como se indica en la captura anterior, habrá que insertar el comando <strong>opencode </strong>desde el directorio en el que se encuentra. Entonces se mostrará la interfaz de OpenCode.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/5/IMG-20260123-WA0002.jpg\" alt=\"\" width=\"620\" height=\"349\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0002-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0002-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0002-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0002-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0002-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0002-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p class=\"align-center\"><strong>Paso 3</strong></p>\n<p>Antes de hacer nada en esta pantalla, volveremos a la terminal y crearemos el archivo <strong>opencode.json</strong> en el directorio de OpenCode. El archivo es el siguiente:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/5/IMG-20260123-WA0003.jpg\" alt=\"\" width=\"627\" height=\"353\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0003-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0003-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0003-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0003-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0003-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0003-2xl.jpg 1920w\"></figure>\n<p>Lo que hace este archivo es indicar a OpenCode que se establecerá <strong>Ollama</strong> como proveedor de IA, y que se usará especificamente el modelo <strong>GPT OSS 20B</strong> para trabajar.</p>\n<p> </p>\n<p class=\"align-center\"><strong>Paso 4</strong></p>\n<p>Volviendo a la interfaz de OpenCode del paso 2, al escribir en el cuadro de texto <strong>/models</strong> se nos mostrará todos los modelos disponibles con los que podemos trabajar. Entre ellos encontraremos el que instalamos en el paso anterior, con el nombre especificado en el .json (<strong>gpt-oss:20b</strong>), bajo el apartado con el nombre establecido en el mismo archivo (<strong>Ollama (local)</strong>).</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/5/IMG-20260123-WA0004.jpg\" alt=\"\" width=\"624\" height=\"351\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0004-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0004-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0004-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0004-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0004-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0004-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p class=\"align-center\"><strong>Paso 5</strong></p>\n<p>Cargamos el modelo y podremos empezar a usarlo. En nuestro caso le pedimos un calculo para sacar los 100 primeros números primos en distintos lenguajes. </p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/5/IMG-20260123-WA0005.jpg\" alt=\"\" width=\"627\" height=\"353\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0005-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0005-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0005-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0005-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0005-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0005-2xl.jpg 1920w\"></figure>\n<p> </p>\n<hr>\n<p class=\"align-center\"><strong>Capturas de proceso con distinto modelo</strong></p>\n<p> </p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/5/IMG-20260123-WA0008.jpg\" alt=\"\" width=\"620\" height=\"349\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0008-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0008-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0008-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0008-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0008-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0008-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/5/IMG-20260123-WA0007.jpg\" alt=\"\" width=\"620\" height=\"349\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0007-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0007-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0007-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0007-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0007-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0007-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/5/IMG-20260123-WA0009.jpg\" alt=\"\" width=\"620\" height=\"349\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0009-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0009-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0009-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0009-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0009-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/5/responsive/IMG-20260123-WA0009-2xl.jpg 1920w\"></figure>",
            "author": {
                "name": "Carla"
            },
            "tags": [
            ],
            "date_published": "2026-02-01T16:12:44+01:00",
            "date_modified": "2026-02-01T17:21:34+01:00"
        },
        {
            "id": "https://carla38.github.io/2damasi/manual-cuantizacion.html",
            "url": "https://carla38.github.io/2damasi/manual-cuantizacion.html",
            "title": "Manual Cuantización",
            "summary": "En esta tarea se documentará el proceso seguido para realizar la cuantización del modelo Qwen3-8B. Para realizar esta tarea, primero se le pidió a la IA una guía paso a paso en la que pudieramos apoyarnos y entender qué estábamos haciendo en cada momento. También&hellip;",
            "content_html": "<p class=\"align-center\">En esta tarea se documentará el proceso seguido para realizar la cuantización del modelo <strong>Qwen3-8B</strong>. Para realizar esta tarea, primero se le pidió a la IA una guía paso a paso en la que pudieramos apoyarnos y entender qué estábamos haciendo en cada momento. También hay que aclarar que hicimos esta práctica en Windows, ya que en Mac estábamos teniendo problemas con algunos de los comandos.</p>\n<p> </p>\n<p class=\"align-center\"><strong>Paso 1</strong></p>\n<p class=\"align-center\">Lo primero fue crear la estructura de carpetas, en nuestro caso las creamos directamente desde la terminal usando el comando <strong>-mkdir</strong>:</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/4/IMG-20260115-WA0006.jpg\" alt=\"\" width=\"466\" height=\"387\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0006-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0006-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0006-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0006-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0006-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0006-2xl.jpg 1920w\"></figure>\n<p class=\"align-center\"> </p>\n<p class=\"align-center\"><strong>Paso 2</strong></p>\n<p class=\"align-center\">Lo siguiente era descargar <strong>Python</strong>, lo cual tuvimos que hacer manualmente porque el comando no funcionaba.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/4/IMG-20260115-WA0008.jpg\" alt=\"\" width=\"458\" height=\"333\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0008-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0008-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0008-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0008-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0008-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0008-2xl.jpg 1920w\"></figure>\n<p class=\"align-center\">Después instalamos las librerías con los comandos mostrados en la captura: </p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/4/IMG-20260115-WA0009.jpg\" alt=\"\" width=\"1433\" height=\"299\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0009-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0009-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0009-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0009-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0009-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0009-2xl.jpg 1920w\"></figure>\n<p class=\"align-center\"> </p>\n<p class=\"align-center\"><strong>Paso 3</strong></p>\n<p class=\"align-center\">Con el siguiente script se descarga el motor <strong>llama.cpp</strong>, específicamente la versión CUDA 12, para la RTX 4060.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/4/IMG-20260115-WA0010.jpg\" alt=\"\" width=\"634\" height=\"328\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0010-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0010-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0010-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0010-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0010-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0010-2xl.jpg 1920w\"></figure>\n<p class=\"align-center\"> </p>\n<p class=\"align-center\"><strong>Paso 4</strong></p>\n<p class=\"align-center\">Con este comando hemos descargado el modelo <strong>Qwen-8B</strong> (16GB) directamente en una de las carpertas creadas al inicio.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/4/IMG-20260115-WA0011.jpg\" alt=\"\" width=\"643\" height=\"142\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0011-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0011-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0011-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0011-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0011-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0011-2xl.jpg 1920w\"></figure>\n<p class=\"align-center\"> </p>\n<p class=\"align-center\"><strong>Paso 5</strong></p>\n<p class=\"align-center\">Este paso es el esencial para la cuantización: se le pasa al modelo un texto, el cual se repetirá un número de veces indicado, en nuestro caso 100. Entonces, se identificarán las partes del modelo que son críticas para su funcionamiento, y más adelante se cuantizarán de manera que no las afecte negativamente.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/4/IMG-20260115-WA0012.jpg\" alt=\"\" width=\"1593\" height=\"277\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0012-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0012-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0012-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0012-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0012-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0012-2xl.jpg 1920w\"></figure>\n<p class=\"align-center\"> </p>\n<p class=\"align-center\"><strong>Paso 6</strong></p>\n<p class=\"align-center\">Se ejecuta <strong>llama-imatrix</strong>, que generará el archivo <strong>Qwen3-8B.imatrix.dat</strong>, el cual contiene información sobre qué partes de dicho modelo son las más sensibles, y ayudará a guiar la cuantización.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/4/IMG-20260115-WA0013.jpg\" alt=\"\" width=\"542\" height=\"324\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0013-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0013-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0013-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0013-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0013-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0013-2xl.jpg 1920w\"></figure>\n<p class=\"align-center\"> </p>\n<p class=\"align-center\"><strong>Paso 7</strong></p>\n<p class=\"align-center\">Usamos este comando para hacer una comprobación rápida de que se ha creado el archivo anterior correctamente:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/4/IMG-20260115-WA0015.jpg\" alt=\"\" width=\"595\" height=\"144\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0015-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0015-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0015-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0015-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0015-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0015-2xl.jpg 1920w\"></figure>\n<p class=\"align-center\"> </p>\n<p class=\"align-center\"><strong>Paso 8</strong></p>\n<p class=\"align-center\">Finalmente, con el siguiente comando y usando el archivo Qwen3-8B.imatrix.dat, se realizará la cuantización del modelo:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/4/IMG-20260115-WA0015-2.jpg\" alt=\"\" width=\"614\" height=\"112\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0015-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0015-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0015-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0015-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0015-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0015-2-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/4/IMG-20260115-WA0016.jpg\" alt=\"\" width=\"615\" height=\"426\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0016-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0016-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0016-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0016-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0016-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0016-2xl.jpg 1920w\"></figure>\n<p class=\"align-center\"> </p>\n<p class=\"align-center\"><strong>Comprobación</strong></p>\n<p class=\"align-center\">Solo queda probar el modelo para comprobar que el proceso ha funcionado. Cargamos el archivo resultante del paso anterior en LMStudio, y como se puede comprobar en la imagen, el modelo Qwen3-8B cargado pesa únicamente <strong>3.28GB</strong>, pesando el original <strong>16GB</strong>.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/4/IMG-20260115-WA0017.jpg\" alt=\"\" width=\"646\" height=\"276\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0017-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0017-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0017-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0017-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0017-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0017-2xl.jpg 1920w\"></figure>\n<p class=\"align-center\">Cargamos un chat con este modelo y le pedimos que nos cuente un cuento, siendo este el resultado de la prueba y el fin del proceso de cuantización:</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/4/IMG-20260115-WA0018.jpg\" alt=\"\" width=\"645\" height=\"446\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0018-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0018-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0018-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0018-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0018-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/4/responsive/IMG-20260115-WA0018-2xl.jpg 1920w\"></figure>",
            "author": {
                "name": "Carla"
            },
            "tags": [
            ],
            "date_published": "2026-01-18T18:33:12+01:00",
            "date_modified": "2026-01-18T18:45:41+01:00"
        },
        {
            "id": "https://carla38.github.io/2damasi/comparativa-de-modelos.html",
            "url": "https://carla38.github.io/2damasi/comparativa-de-modelos.html",
            "title": "Comparativa de Modelos",
            "summary": "Comparativa de Modelos - Carla Arribas Muñoz El objetivo de esta práctica ha sido poner a prueba distintos modelos de IA en LM Studio pasándoles algunos arcetijos. En base a sus respuestas, y teniendo en cuenta los tokens por segundo, tokens totales, tiempo de respuesta,&hellip;",
            "content_html": "<p class=\"align-center\"><span style=\"text-decoration: underline;\"><span style=\"color: #000000; text-decoration: underline;\"><strong>Comparativa de Modelos - Carla Arribas Muñoz</strong></span></span></p>\n<p>El objetivo de esta práctica ha sido poner a prueba distintos modelos de IA en LM Studio pasándoles algunos arcetijos. En base a sus respuestas, y teniendo en cuenta los tokens por segundo, tokens totales, tiempo de respuesta, etc.., hemos hecho una comparativa de los distintos modelos probados.</p>\n<p class=\"align-left\">Por falta de tiempo, únicamente pudimos probar 3 acertijos en 2 modelos distintos. Pero para está práctica también se incluirá una prueba realizada desde la Jetson Nano, en la cuál, desde la terminal usando Ollama, pedimos a la IA que nos contara un cuento.</p>\n<p> </p>\n<p class=\"align-center\"><strong>Ollama</strong></p>\n<p class=\"align-left\">Para installar Ollama en la Jetson Nano (Linux) habrá que introducir el siguiente comando:</p>\n<p class=\"align-left\"><strong>curl -fsSL https://ollama.com/install.sh | sh</strong></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0002.jpg\" alt=\"\" width=\"558\" height=\"314\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0002-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0002-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0002-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0002-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0002-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0002-2xl.jpg 1920w\"></figure>\n<p class=\"align-left\">Al acabar la instalación, podremos ejecutar cualquiera de los modelos que ofrecen. En nuestro caso ejecutamos el modelo Qwen3 8B usando el siguiente comando:</p>\n<p class=\"align-left\"><strong>ollama run qwen3:8b --verbose</strong></p>\n<p class=\"align-left\">El prompt que le dimos a la IA en este caso fue que nos contara un cuento de 500 palabras. En esta captura se muestra su respuesta junto a otra información, como la duración y los tokens:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0008.jpg\" alt=\"\" width=\"560\" height=\"315\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0008-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0008-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0008-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0008-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0008-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0008-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p class=\"align-center\"><strong>LM Studio</strong></p>\n<p>Desde la Mac Mini hicimos las pruebas con 2 modelos en LM Studio. Usamos los modelos Granite 4 H Tiny y Qwen VL 4B. Los acertijos propuestos fueron los siguientes:</p>\n<ul>\n<li>Tengo ciudades, pero no casas; tengo montañas, pero no árboles; tengo agua, pero no peces. ¿Qué soy?</li>\n<li>Cuanto más quitas, más grande se hace. ¿Qué es?</li>\n<li>No tiene boca pero habla, no tiene oídos pero escucha. Si lo llamas, responde. ¿Qué es?</li>\n</ul>\n<p><strong>-Respuestas de Granite 4H Tiny</strong></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0011.jpg\" alt=\"\" width=\"567\" height=\"319\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0011-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0011-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0011-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0011-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0011-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0011-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0012.jpg\" alt=\"\" width=\"569\" height=\"320\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0012-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0012-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0012-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0012-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0012-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0012-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0013.jpg\" alt=\"\" width=\"567\" height=\"319\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0013-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0013-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0013-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0013-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0013-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0013-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p><strong>-Respuestas de Qwen VL 4B</strong></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0015-2.jpg\" alt=\"\" width=\"567\" height=\"596\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0015-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0015-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0015-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0015-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0015-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0015-2-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0016.jpg\" alt=\"\" width=\"566\" height=\"625\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0016-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0016-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0016-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0016-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0016-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0016-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/3/IMG-20251205-WA0017.jpg\" alt=\"\" width=\"565\" height=\"649\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0017-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0017-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0017-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0017-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0017-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/3/responsive/IMG-20251205-WA0017-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p class=\"align-center\"><strong>Conclusiones</strong></p>\n<p>Como conclusión general a partir de las capturas, se puede observar que tanto Qwen3 8B en la Jetson como Granite en LM Studio han sido capaces de dar una respuesta acorde a lo solicitado, mientras que Qwen3 4B ha entrado en un bucle para los 2 últimos acertijos, teniendo que ser detenido directamente por nosotros. Los resultados finales han sido los siguientes:</p>\n<p><strong>Qwen 3 8B</strong></p>\n<ul>\n<li>Tokens por segundo : 7,68 tk/s</li>\n<li>Tokens totales : 1175 tks</li>\n</ul>\n<p><strong>Granite 4H Tiny</strong></p>\n<p>-<span style=\"text-decoration: underline;\"><span style=\"color: #000000; text-decoration: underline;\">Acertijo 1</span></span></p>\n<ul>\n<li>Tokens por segundo : 44,48 tk/s</li>\n<li>Tokens totales : 49 tks</li>\n<li>Tiempo primer token : 0,24 s</li>\n<li>Respuesta : Acertada</li>\n</ul>\n<p>-<span style=\"text-decoration: underline;\">Acertijo 2</span></p>\n<ul>\n<li>Tokens por segundo : 45.70 tk/s</li>\n<li>Tokens totales : 32 tks</li>\n<li>Tiempo primer token : 0,38 s</li>\n<li>Respuesta : Acertada</li>\n</ul>\n<p>-<span style=\"text-decoration: underline;\">Acertijo 3</span></p>\n<ul>\n<li>Tokens por segundo : 44,78 tk/s</li>\n<li>Tokens totales : 50 tks</li>\n<li>Tiempo primer token : 0,20 s</li>\n<li>Respuesta : Acertada</li>\n</ul>\n<p><strong>Qwen 3 4B</strong></p>\n<p>-<span style=\"text-decoration: underline;\">Acertijo 1</span></p>\n<ul>\n<li>Tokens por segundo : 39,18 tk/s</li>\n<li>Tokens totales : 520 tks</li>\n<li>Tiempo primer token : 0,58 s</li>\n<li>Respuesta : Acertada</li>\n</ul>\n<p>-<span style=\"text-decoration: underline;\">Acertijo 2</span></p>\n<ul>\n<li>Tokens por segundo : 35,22 tk/s</li>\n<li>Tokens totales : 1372 tks</li>\n<li>Tiempo primer token : 2,46 s</li>\n<li>Respuesta : Fallida. Bucle.</li>\n</ul>\n<p>-<span style=\"text-decoration: underline;\">Acertijo 3</span></p>\n<ul>\n<li>Tokens por segundo : 32,09 tk/s</li>\n<li>Tokens totales : 626 tks</li>\n<li>Tiempo primer token : 6,18 s</li>\n<li>Respuesta : Fallida. Bucle.</li>\n</ul>\n<p> </p>\n<p> </p>\n<p> </p>",
            "author": {
                "name": "Carla"
            },
            "tags": [
            ],
            "date_published": "2025-12-07T00:07:51+01:00",
            "date_modified": "2025-12-07T20:14:20+01:00"
        },
        {
            "id": "https://carla38.github.io/2damasi/configuracion-inicial-jetson-nano.html",
            "url": "https://carla38.github.io/2damasi/configuracion-inicial-jetson-nano.html",
            "title": "Configuración Inicial Jetson Nano",
            "summary": "Configuración Inicial Jetson Nano - Carla Arribas Muñoz Para esta práctica documentaré el proceso seguido para la configuración de la Jetson Orin Nano en el dispositivo del aula. Lo primero antes de conectarla al ordenador ha sido introducir una tarjeta SD en la Jetson. Tras&hellip;",
            "content_html": "<p class=\"align-center\"><strong><span style=\"text-decoration: underline;\">Configuración Inicial Jetson Nano - Carla Arribas Muñoz</span></strong></p>\n<p>Para esta práctica documentaré el proceso seguido para la configuración de la Jetson Orin Nano en el dispositivo del aula.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251120-WA0002.jpg\" alt=\"\" width=\"526\" height=\"296\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0002-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0002-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0002-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0002-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0002-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0002-2xl.jpg 1920w\"></figure>\n<p>Lo primero antes de conectarla al ordenador ha sido introducir una tarjeta SD en la Jetson. Tras ello hemos podido conectarla y comenzar con la configuración.</p>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\">\n<tbody>\n<tr>\n<td style=\"width: 49.943%;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251120-WA0004-2.jpg\" alt=\"\" width=\"274\" height=\"271\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0004-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0004-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0004-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0004-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0004-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0004-2-2xl.jpg 1920w\"></figure>\n</td>\n<td style=\"width: 49.943%;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251120-WA0003.jpg\" alt=\"\" width=\"1599\" height=\"899\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0003-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0003-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0003-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0003-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0003-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0003-2xl.jpg 1920w\"></figure>\n</td>\n</tr>\n<tr>\n<td style=\"width: 49.943%;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251120-WA0005.jpg\" alt=\"\" width=\"1599\" height=\"899\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0005-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0005-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0005-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0005-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0005-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0005-2xl.jpg 1920w\"></figure>\n</td>\n<td style=\"width: 49.943%;\"> \n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251120-WA0008.jpg\" alt=\"\" width=\"289\" height=\"304\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0008-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0008-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0008-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0008-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0008-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0008-2xl.jpg 1920w\"></figure>\n</td>\n</tr>\n</tbody>\n</table>\n<p>El sistema operativo era Ubuntu, asi que seguimos las instrucciones habituales para su configuración: idioma, región, Wi-Fi y creación de usuario:</p>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\">\n<tbody>\n<tr>\n<td style=\"width: 49.943%;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251120-WA0011.jpg\" alt=\"\" width=\"1599\" height=\"899\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0011-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0011-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0011-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0011-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0011-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0011-2xl.jpg 1920w\"></figure>\n</td>\n<td style=\"width: 49.943%;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251120-WA0013.jpg\" alt=\"\" width=\"1599\" height=\"899\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0013-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0013-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0013-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0013-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0013-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0013-2xl.jpg 1920w\"></figure>\n</td>\n</tr>\n<tr>\n<td style=\"width: 49.943%;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251120-WA0012.jpg\" alt=\"\" width=\"1599\" height=\"899\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0012-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0012-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0012-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0012-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0012-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0012-2xl.jpg 1920w\"></figure>\n</td>\n<td style=\"width: 49.943%;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251120-WA0014.jpg\" alt=\"\" width=\"1599\" height=\"899\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0014-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0014-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0014-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0014-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0014-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251120-WA0014-2xl.jpg 1920w\"></figure>\n</td>\n</tr>\n</tbody>\n</table>\n<p>Tras este proceso, nos hemos dirigido a la página <strong>NVIDIA Jetson AI Lab </strong>y hemos seguido las instrucciones que ofrecen para instalar el disco SSD en la Jetson, y así congifurarla para el uso de IA.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251127-WA0002.jpg\" alt=\"\" width=\"537\" height=\"302\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0002-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0002-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0002-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0002-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0002-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0002-2xl.jpg 1920w\"></figure>\n<p>Hemos abierto la terminal y ahí hemos ido copiando los comandos en el orden que indica la web.</p>\n<p>-<strong>lspci</strong>. Lista los distintos puertos PCI de la Jetson.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251127-WA0003.jpg\" alt=\"\" width=\"565\" height=\"318\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0003-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0003-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0003-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0003-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0003-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0003-2xl.jpg 1920w\"></figure>\n<p>-<strong>lsblk</strong>. Lista el nombre de los distintos dispositivos. El que corresponde al SSD, en nuestro caso fue nvme0n1.</p>\n<p>-<strong>sudo mkfs.ext4 /dev/nvme0n1</strong>. Formatea el SSD</p>\n<p>-<strong>sudo mkdir /ssd</strong>. Crea un punto de montaje.</p>\n<p>-<strong>sudo mount /dev/nvme0n1 /ssd</strong>. Monta el SSD.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251127-WA0004.jpg\" alt=\"\" width=\"566\" height=\"318\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0004-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0004-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0004-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0004-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0004-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0004-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251127-WA0005.jpg\" alt=\"\" width=\"563\" height=\"317\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0005-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0005-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0005-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0005-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0005-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0005-2xl.jpg 1920w\"></figure>\n<p>-<strong>lsblk -f</strong>. Nos indica el UUID (Identificador Único Universal) de nuestra SSD.</p>\n<p>-<strong>sudo vi /etc/fstab</strong>. Se crea una nueva entrada en el archivo fstab (File System Table), archivo de configuración que indica como se deben montar los sistemas y archivos al iniciar el sistema.</p>\n<p>-<strong>UUID=************-****-****-****-******** /ssd/ ext4 defaults 0 2</strong>. Insertamos esta línea, sustituyéndola con el UUID que obtuvimos anteriormente.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251127-WA0006.jpg\" alt=\"\" width=\"544\" height=\"306\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0006-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0006-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0006-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0006-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0006-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0006-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251127-WA0007.jpg\" alt=\"\" width=\"544\" height=\"306\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0007-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0007-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0007-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0007-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0007-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0007-2xl.jpg 1920w\"></figure>\n<p>-sudo chown ${USER}:${USER} /ssd. Cambia el dueño del directorio /ssd.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251127-WA0008.jpg\" alt=\"\" width=\"542\" height=\"305\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0008-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0008-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0008-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0008-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0008-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0008-2xl.jpg 1920w\"></figure>\n<p>Con esto quedaría configurada la Jetson Nano.</p>\n<p>Al acabar, comenzamos la instalación de LM Studio.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251127-WA0009.jpg\" alt=\"\" width=\"540\" height=\"304\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0009-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0009-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0009-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0009-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0009-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0009-2xl.jpg 1920w\"></figure>\n<p>Como el archivo descargado era un AppImage, tuvimos que dar permiso para ejecutarlo. Pese a ello, tuvimos un problema el cual no permitía iniciar la aplicación. Para solucionarlo tuvimos que abrir la terminal e insertar los siguientes comandos: <strong>sudo apt install libfuse2</strong> y <strong>sudo apt install fuse3.</strong></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251127-WA0010.jpg\" alt=\"\" width=\"544\" height=\"306\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0010-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0010-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0010-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0010-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0010-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0010-2xl.jpg 1920w\"></figure>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\">\n<tbody>\n<tr>\n<td style=\"width: 49.943%;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251127-WA0011.jpg\" alt=\"\" width=\"379\" height=\"213\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0011-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0011-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0011-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0011-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0011-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0011-2xl.jpg 1920w\"></figure>\n</td>\n<td style=\"width: 49.943%;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251127-WA0012.jpg\" alt=\"\" width=\"1920\" height=\"1080\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0012-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0012-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0012-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0012-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0012-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0012-2xl.jpg 1920w\"></figure>\n</td>\n</tr>\n</tbody>\n</table>\n<p>Tras solucionarlo, pudimos iniciar LM Studio e hicimos unas primeras pruebas.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/2/IMG-20251127-WA0016.jpg\" alt=\"\" width=\"617\" height=\"347\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0016-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0016-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0016-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0016-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0016-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/2/responsive/IMG-20251127-WA0016-2xl.jpg 1920w\"></figure>",
            "author": {
                "name": "Carla"
            },
            "tags": [
            ],
            "date_published": "2025-12-04T11:15:39+01:00",
            "date_modified": "2025-12-04T12:14:48+01:00"
        },
        {
            "id": "https://carla38.github.io/2damasi/configuracion-raspberry-pi-y-mac-mini.html",
            "url": "https://carla38.github.io/2damasi/configuracion-raspberry-pi-y-mac-mini.html",
            "title": "Configuración Raspberry Pi y Mac Mini",
            "summary": "Configuración Raspberry Pi y Mac Mini Índice 1.- Introducción 2.- Configuración Raspberry Pi 3.- Configuración Mac Mini 1.- Introducción El objetivo de esta práctica será documentar el proceso seguido para configurar una Raspberry Pi y un Mac Mini en los equipos del taller. Se acompañará&hellip;",
            "content_html": "<p><span style=\"color: #000000;\"><strong><span style=\"text-decoration: underline;\">Configuración Raspberry Pi y Mac Mini</span> </strong></span></p>\n<p><span style=\"text-decoration: underline;\"><strong>Índice</strong></span></p>\n<p><span style=\"font-weight: 400;\">1.- Introducción</span></p>\n<p><span style=\"font-weight: 400;\">2.- Configuración Raspberry Pi</span></p>\n<p><span style=\"font-weight: 400;\">3.- Configuración Mac Mini</span></p>\n<p> </p>\n<p><br><span style=\"text-decoration: underline;\"><strong>1.- Introducción</strong></span></p>\n<p><span style=\"font-weight: 400;\">El objetivo de esta práctica será documentar el proceso seguido para configurar una Raspberry Pi y un Mac Mini en los equipos del taller. Se acompañará de imágenes para mostrar los pasos que se han seguido.</span></p>\n<p> </p>\n<p><span style=\"text-decoration: underline;\"><span style=\"color: #000000; text-decoration: underline;\"><strong>2.- Configuración Raspberry Pi</strong></span></span></p>\n<p><span style=\"font-weight: 400;\">Primero comenzamos con la configuración de la Raspberry Pi, conectando el teclado al equipo. Lo primero que aparecerá será una pantalla indicando que habrá que realizar unas configuraciones antes de comenzar a usar el escritorio de Raspberry Pi.</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0005.jpg\" alt=\"\" width=\"586\" height=\"330\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0005-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0005-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0005-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0005-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0005-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0005-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p><span style=\"font-weight: 400;\">El proceso de configuración ha sido el siguiente: Primero elegimos el país, idioma y zona horaria. Después creamos el usuario, con el nombre y contraseña indicados en el aula. Elegimos la red WiFi. En nuestro caso elegimos instalar Chromium como navegador por defecto.</span></p>\n<p><span style=\"font-weight: 400;\">Tras este proceso, habrá que actualizar el software.</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0006-2.jpg\" alt=\"\" width=\"578\" height=\"325\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0006-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0006-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0006-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0006-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0006-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0006-2-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0008-2.jpg\" alt=\"\" width=\"576\" height=\"324\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0008-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0008-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0008-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0008-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0008-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0008-2-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0009.jpg\" alt=\"\" width=\"578\" height=\"325\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0009-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0009-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0009-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0009-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0009-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0009-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0011.jpg\" alt=\"\" width=\"576\" height=\"324\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0011-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0011-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0011-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0011-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0011-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0011-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image align-left\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0013.jpg\" alt=\"\" width=\"580\" height=\"326\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0013-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0013-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0013-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0013-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0013-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0013-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p><span style=\"font-weight: 400;\">Al acabar esta descarga, la Raspberry Pi queda lista para usar.</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0014-2.jpg\" alt=\"\" width=\"579\" height=\"326\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0014-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0014-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0014-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0014-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0014-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0014-2-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0015-2.jpg\" alt=\"\" width=\"578\" height=\"325\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0015-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0015-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0015-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0015-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0015-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0015-2-2xl.jpg 1920w\"></figure>\n<p><br><br></p>\n<p><span style=\"text-decoration: underline;\"><strong>3.- Configuración Mac Mini</strong></span></p>\n<p><span style=\"font-weight: 400;\">Para configurar el Mac Mini desconectamos la Raspberry y usamos otro teclado para conectarlo al Mac Mini. </span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0017.jpg\" alt=\"\" width=\"610\" height=\"343\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0017-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0017-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0017-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0017-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0017-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0017-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p><span style=\"font-weight: 400;\">El proceso de configuración va a ser muy similar al anterior. Primero nos preguntarán por el idioma y la región, además de otras opciones de personalización.</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0022-2.jpg\" alt=\"\" width=\"606\" height=\"341\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0022-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0022-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0022-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0022-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0022-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0022-2-2xl.jpg 1920w\"></figure>\n<p><span style=\"font-weight: 400;\">Obviando algunas opciones de personalización extra, como ubicación, privacidad o cuenta Apple, y la aceptación de Términos y Condiciones, podremos seleccionar la red WiFi y crear nuestro usuario, que será igual al del apartado anterior.</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0025-2.jpg\" alt=\"\" width=\"610\" height=\"343\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0025-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0025-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0025-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0025-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0025-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0025-2-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0032-2.jpg\" alt=\"\" width=\"608\" height=\"342\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0032-2-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0032-2-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0032-2-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0032-2-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0032-2-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0032-2-2xl.jpg 1920w\"></figure>\n<p> </p>\n<p><span style=\"font-weight: 400;\">Tras esto habremos configurado el Mac Mini. Tras haber acabado, conectamos a través de Bluetooth el teclado y ratón POP. Además instalamos LM Studio para hacer unas primeras pruebas.</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0040.jpg\" alt=\"\" width=\"613\" height=\"345\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0040-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0040-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0040-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0040-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0040-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0040-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://carla38.github.io/2damasi/media/posts/1/IMG-20251113-WA0042.jpg\" alt=\"\" width=\"613\" height=\"345\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0042-xs.jpg 640w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0042-sm.jpg 768w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0042-md.jpg 1024w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0042-lg.jpg 1366w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0042-xl.jpg 1600w ,https://carla38.github.io/2damasi/media/posts/1/responsive/IMG-20251113-WA0042-2xl.jpg 1920w\"></figure>",
            "author": {
                "name": "Carla"
            },
            "tags": [
            ],
            "date_published": "2025-11-24T22:45:19+01:00",
            "date_modified": "2025-11-24T23:00:23+01:00"
        }
    ]
}
