<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Manual Fine Tunning - DocumentacionASI</title><meta name="description" content="En este manual se documentará el proceso seguido durante la práctica del Fine Tunning. El Fine Tunning en Inteligencia Artificial consiste en ajustar un modelo preexistente para que aprenda nueva información o pueda desarrollar tareas específicas. Para esta tarea el modelo que hemos elegido para&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://carla38.github.io/2damasi/manual-fine-tunning.html"><link rel="alternate" type="application/atom+xml" href="https://carla38.github.io/2damasi/feed.xml" title="DocumentacionASI - RSS"><link rel="alternate" type="application/json" href="https://carla38.github.io/2damasi/feed.json" title="DocumentacionASI - JSON"><meta property="og:title" content="Manual Fine Tunning"><meta property="og:site_name" content="DocumentacionASI"><meta property="og:description" content="En este manual se documentará el proceso seguido durante la práctica del Fine Tunning. El Fine Tunning en Inteligencia Artificial consiste en ajustar un modelo preexistente para que aprenda nueva información o pueda desarrollar tareas específicas. Para esta tarea el modelo que hemos elegido para&hellip;"><meta property="og:url" content="https://carla38.github.io/2damasi/manual-fine-tunning.html"><meta property="og:type" content="article"><link rel="stylesheet" href="https://carla38.github.io/2damasi/assets/css/style.css?v=7d5bbddb88a13bb0ad0ef21985ae0d0a"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://carla38.github.io/2damasi/manual-fine-tunning.html"},"headline":"Manual Fine Tunning","datePublished":"2026-02-08T23:23+01:00","dateModified":"2026-02-18T01:11+01:00","description":"En este manual se documentará el proceso seguido durante la práctica del Fine Tunning. El Fine Tunning en Inteligencia Artificial consiste en ajustar un modelo preexistente para que aprenda nueva información o pueda desarrollar tareas específicas. Para esta tarea el modelo que hemos elegido para&hellip;","author":{"@type":"Person","name":"Carla","url":"https://carla38.github.io/2damasi/authors/carla/"},"publisher":{"@type":"Organization","name":"Carla"}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="post-template"><header class="top js-header"><a class="logo" href="https://carla38.github.io/2damasi/">DocumentacionASI</a></header><main class="post"><article class="content"><div class="hero hero--noimage"><header class="hero__content"><div class="wrapper"><h1>Manual Fine Tunning</h1><div class="feed__meta content__meta"><time datetime="2026-02-08T23:23" class="feed__date">February 8, 2026</time></div></div></header></div><div class="entry-wrapper content__entry"><p class="align-center">En este manual se documentará el proceso seguido durante la práctica del <strong>Fine Tunning</strong>.</p><p class="align-center">El Fine Tunning en Inteligencia Artificial consiste en ajustar un modelo preexistente para que aprenda nueva información o pueda desarrollar tareas específicas.</p><p class="align-center">Para esta tarea el modelo que hemos elegido para realizar el Fine Tunning es <strong>Llama-3.2-1B.</strong></p><hr><p class="align-center"><strong>Paso 1</strong></p><p class="align-center">Previamente hemos preparado un directorio en el que guardará el modelo resultante del proceso y un archivo <strong>.json</strong> con los nuevos datos que aprenderá el modelo. </p><p class="align-center">Primero, usando el comando <strong>python3 -m pip install mlx-lm huggingface_hub</strong> descargamos las librerías necesarias.</p><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/7/IMG-20260130-WA0001.jpg" alt="" width="636" height="358" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0001-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0001-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0001-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0001-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0001-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0001-2xl.jpg 1920w"></figure><p class="align-center"> </p><p class="align-center"><strong>Paso 2</strong></p><p class="align-center">Con <strong>cp train.jsonl valid.jsonl</strong> se crea una copia de los datos, ya que <strong>MLX</strong>, la librería que se está usando para el entrenamiento, requiere un set de validación.</p><p class="align-center">El segundo comando que se muestra en la captura lanza el proceso de entrenamiento. En la captura se muestran 100 iteraciones, pero más tarde se incrementaron para que el modelo pudiera aprender mejor la nueva información.</p><p class="align-center">Al acabar, guarda los adapters, el conocimiento nuevo, en la carpeta <strong>adapters</strong></p><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/7/IMG-20260130-WA0003.jpg" alt="" width="645" height="363" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0003-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0003-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0003-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0003-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0003-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0003-2xl.jpg 1920w"></figure><p class="align-center"> </p><p class="align-center"><strong>Paso 3</strong></p><p class="align-center">Se ejecuta un proceso de fusión que une el modelo original con los adapters generados en el paso anterior, dando como resultado un modelo nuevo derivado del original pero con la nueva información. Este modelo se guarda en la carpeta <strong>modelo-daniel-fusionado</strong>.</p><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/7/IMG-20260130-WA0004-2.jpg" alt="" width="638" height="148" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0004-2-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0004-2-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0004-2-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0004-2-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0004-2-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0004-2-2xl.jpg 1920w"></figure><p class="align-center"> </p><p class="align-center"><strong>Paso 5</strong></p><p class="align-center">Se instalan dependencias necesarias para convertir el modelo a formato <strong>.gguf</strong>.</p><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/7/IMG-20260130-WA0005-2.jpg" alt="" width="649" height="365" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0005-2-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0005-2-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0005-2-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0005-2-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0005-2-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0005-2-2xl.jpg 1920w"></figure><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/7/IMG-20260130-WA0006.jpg" alt="" width="645" height="363" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0006-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0006-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0006-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0006-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0006-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0006-2xl.jpg 1920w"></figure><p class="align-center"> </p><p class="align-center"><strong>Prueba Final</strong></p><p class="align-center">Ejecutando el siguiente comando: </p><p class="align-center"><strong>python3 -m mlx_lm.chat \</strong><br><strong>--model mlx-community/Llama-3.2-1B-Instruct-4bit \</strong><br><strong>--adapter-path adapters</strong> </p><p class="align-center">Se abrirá una interfaz para poder chatear con el modelo. Al preguntarle '¿Quién es Daniel Terroba?', el modelo responde con la información que ha aprendido del entrenamiento.</p><figure class="post__image"><img loading="lazy" src="https://carla38.github.io/2damasi/media/posts/7/IMG-20260130-WA0009.jpg" alt="" width="665" height="374" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0009-xs.jpg 640w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0009-sm.jpg 768w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0009-md.jpg 1024w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0009-lg.jpg 1366w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0009-xl.jpg 1600w, https://carla38.github.io/2damasi/media/posts/7/responsive/IMG-20260130-WA0009-2xl.jpg 1920w"></figure><p class="align-center"> </p></div></article></main><footer class="footer"><div class="wrapper"><div class="footer__copyright"><p>DocumentacionASI - Carla Arribas</p></div><button id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg width="20" height="20"><use xlink:href="https://carla38.github.io/2damasi/assets/svg/svg-map.svg#toparrow"/></svg></button></div></footer><script defer="defer" src="https://carla38.github.io/2damasi/assets/js/scripts.min.js?v=700105c316933a8202041b6415abb233"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>